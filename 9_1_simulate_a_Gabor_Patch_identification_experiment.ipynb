{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "9.1.simulate a Gabor Patch identification experiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNLoUdNFlF2xI4zA1v5MAPr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nmningmei/Deep_learning_fMRI_EEG/blob/master/9_1_simulate_a_Gabor_Patch_identification_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdPrtM3JWIQL",
        "colab_type": "text"
      },
      "source": [
        "# Generate Gabor patches and devide them into train and validation sets. The validation set contains the easiest examples, which are close to 45 degrees\n",
        "\n",
        "## function credit: Sanjeev"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xrm7qKJIcrLM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 712
        },
        "outputId": "b83ec071-a01f-49ef-b9e3-8db89eb8d7f2"
      },
      "source": [
        "\"\"\"\n",
        "Created on Fri Nov 22 14:26:17 2019\n",
        "\n",
        "@author: nmei\n",
        "\n",
        "this script is to generate folders of gabor instances.\n",
        "The angles ranges from -89 (left) to 89 (right), while zero is not included,\n",
        "those angles that are close to +/-45 are used for validation\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm import tqdm\n",
        "\n",
        "from joblib import Parallel,delayed\n",
        "import gc\n",
        "gc.collect()\n",
        "\n",
        "# number of pixels per axis\n",
        "imSize = 128\n",
        "# 50 lambda values for generating the gabors\n",
        "lamdas = np.linspace(4,32,20)\n",
        "# 300 degrees between -89 to 89 degree\n",
        "thetaRads = np.linspace(-89,89,20)\n",
        "# plot of the generated gabors\n",
        "figure_dir = 'data/gabors/small'\n",
        "if not os.path.exists(figure_dir):\n",
        "    os.makedirs(figure_dir)\n",
        "\n",
        "def generator(lamda = 4, thetaRad_base = 45,figure_dir = 'data/gabors'):\n",
        "    \"\"\"\n",
        "    Inputs\n",
        "    -------------\n",
        "    lamda: float, better be in range between 4 and 32\n",
        "    thetaRad_base:float, base value of theta, in degrees\n",
        "    figure_dir: string, mother directory of the gabors, will be divided into train\n",
        "            and validation\n",
        "    \"\"\"\n",
        "    if (np.abs(np.abs(thetaRad_base) - 45) < 5): # make easy cases the validation set\n",
        "        folder = 'validation'\n",
        "    else:\n",
        "        folder = 'train'\n",
        "    # identify left and right based on the theta base values\n",
        "    if thetaRad_base < 0:\n",
        "        sub_folder = 'left'\n",
        "    else:\n",
        "        sub_folder = 'right'\n",
        "    # generate the file name based on the parameteres\n",
        "    name = f'{lamda_}_{thetaRad_base}_{sub_folder}.jpg'\n",
        "    saving_name = os.path.join(figure_dir,folder,sub_folder,name)\n",
        "    if not os.path.exists(os.path.join(figure_dir,folder,sub_folder)):\n",
        "        os.makedirs(os.path.join(figure_dir,folder,sub_folder))\n",
        "    # convert degree to pi-based\n",
        "    thetaRad = thetaRad_base * np.pi / 180\n",
        "    # Sanjeev's algorithm\n",
        "    X       = np.arange(imSize)\n",
        "    X0      = (X / imSize) - .5\n",
        "    freq    = imSize / lamda_\n",
        "    Xf      = X0 * freq * 2 * np.pi\n",
        "    sinX    = np.sin(Xf)\n",
        "    Xm,Ym   = np.meshgrid(X0,X0)\n",
        "    Xt      = Xm * np.cos(thetaRad)\n",
        "    Yt      = Ym * np.sin(thetaRad)\n",
        "    XYt     = Xt + Yt\n",
        "    XYf     = XYt * freq * 2 * np.pi\n",
        "\n",
        "    grating = np.sin(XYf)\n",
        "\n",
        "    s       = 0.075\n",
        "    w       = np.exp(-(0.3 * ((Xm**2) + (Ym**2)) / (2 * s**2))) * 2\n",
        "    w[w > 1]= 1\n",
        "    gabor   = ((grating - 0.5) * w) + 0.5\n",
        "\n",
        "    plt.close('all')\n",
        "    fig,ax = plt.subplots(figsize = (6,6))\n",
        "    ax.imshow(gabor,cmap = plt.cm.gray)\n",
        "    ax.axis('off')\n",
        "    plt.close('all')\n",
        "    fig.savefig(saving_name,dpi = 400,bbox_inches = 'tight')\n",
        "    gc.collect() # delete memory garbages\n",
        "\n",
        "for lamda_ in lamdas:\n",
        "    # let's parallelize the for-loop\n",
        "    Parallel(n_jobs = -1,verbose = 1)(delayed(generator)(**{\n",
        "                    'lamda':lamda_,\n",
        "                    'thetaRad_base':thetaRad_base,\n",
        "                    'figure_dir':figure_dir}) for thetaRad_base in thetaRads)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.8s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    8.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    8.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.1s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    8.5s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    8.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    8.7s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    8.9s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    8.5s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    8.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    8.8s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    8.5s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  20 out of  20 | elapsed:    9.0s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyE8e8VTWla8",
        "colab_type": "text"
      },
      "source": [
        "# Train a convolutional neural network to perform the idenfication task by training it with hard examples and validating with easy examples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hci5k5zYWz94",
        "colab_type": "text"
      },
      "source": [
        "## update your tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ut_uqf4d8ro",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install --upgrade tensorflow"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9JPwm-EW2yS",
        "colab_type": "text"
      },
      "source": [
        "## many imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5hM_6vkdJc5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51f13353-5f0b-4e31-d2ff-dacee80d1b63"
      },
      "source": [
        "import numpy      as np\n",
        "import pandas     as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras                           import applications,layers,models,optimizers,losses,regularizers\n",
        "from tensorflow.keras.preprocessing.image       import ImageDataGenerator,random_brightness,load_img,img_to_array\n",
        "\n",
        "from sklearn.metrics                            import roc_auc_score\n",
        "from sklearn.utils                              import shuffle\n",
        "\n",
        "from PIL                                        import Image, ImageEnhance\n",
        "from functools                                  import partial\n",
        "import os\n",
        "from matplotlib                                 import pyplot as plt\n",
        "from tqdm                                       import tqdm\n",
        "\n",
        "from joblib                                     import Parallel,delayed\n",
        "import gc\n",
        "gc.collect()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSnDsKynenKY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9030a46-c27d-45c0-bf15-45cef0a8928e"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pecFiQr_W4iz",
        "colab_type": "text"
      },
      "source": [
        "## some \"hyperparameters\" of the identification task"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xqvbbUhdiTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "working_dir         = 'data/gabors/small'\n",
        "figure_dir          = 'figures/gabors_small'\n",
        "batch_size          = 16\n",
        "image_resize        = 128\n",
        "drop_rate           = 0.25\n",
        "model_name          = 'VGG19_small'\n",
        "model_pretrained    = applications.VGG19\n",
        "preprocess_input    = applications.vgg19.preprocess_input\n",
        "model_dir           = ''\n",
        "patience            = 3\n",
        "loss_func           = losses.binary_crossentropy\n",
        "class_mode          = 'categorical'\n",
        "if not os.path.exists(figure_dir):\n",
        "    os.makedirs(figure_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xqmGg7kXLH3",
        "colab_type": "text"
      },
      "source": [
        "## a preprocessing function to control the noise level and brightness of the images that fed to the convolutional neural network model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg5UmwlSM4qi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_func(xx,noise_level = 0., brightness_level = 1.,):\n",
        "    x = xx.copy()\n",
        "    row,col,ch = x.shape\n",
        "    x /= 255.\n",
        "    mean = 0\n",
        "    sigma = noise_level*0.5\n",
        "    gauss = np.random.normal(mean,sigma,(row,col,ch)).reshape(row,col,ch)\n",
        "    noise_x = x + gauss\n",
        "    noise_x *= 255.\n",
        "    back_to_image = Image.fromarray(np.uint8(noise_x))\n",
        "    #back_to_image = back_to_image.convert('L')\n",
        "    contrast = ImageEnhance.Contrast(back_to_image)\n",
        "    contrast = contrast.enhance(brightness_level) # set FACTOR > 1 to enhance contrast, < 1 to decrease\n",
        "    contrast = preprocess_input(np.array(contrast))\n",
        "    return contrast"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVQxPH0HXUW2",
        "colab_type": "text"
      },
      "source": [
        "## define image generator flow and I still have to write lots of codes for customized training -- because we need to train the network to have some \"ideal\" response to stimuli:\n",
        "\n",
        "1. output 2 differe probabilities and one is higher than the other when the signal is present\n",
        "2. output 2 similar probabilities that are close to 0.5 when the signal is absent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5COWC9xcf4WF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "8db066b9-556f-40b0-82e5-58dc89f783ff"
      },
      "source": [
        "gen             = ImageDataGenerator(\n",
        "                                     preprocessing_function = process_func,\n",
        "                                     )\n",
        "gen_train       = gen.flow_from_directory(os.path.join(working_dir,'train'), # train\n",
        "                                          target_size       = (image_resize,image_resize),  # resize the image\n",
        "                                          batch_size        = 1,                   # batch size\n",
        "                                          class_mode        = class_mode,                # get the labels from the folders\n",
        "                                          shuffle           = False,                         # shuffle for different epochs\n",
        "                                          seed              = 12345,                        # replication purpose\n",
        "                                          )\n",
        "gen_valid       = gen.flow_from_directory(os.path.join(working_dir,'validation'), # validate\n",
        "                                           target_size      = (image_resize,image_resize),  # resize the image\n",
        "                                           batch_size       = 1,                   # batch size\n",
        "                                           class_mode       = class_mode,                # get the labels from the folders\n",
        "                                           shuffle          = False,                         # shuffle for different epochs\n",
        "                                           seed             = 12345,                        # replication purpose\n",
        "                                           )\n",
        "\n",
        "X_train,y_train = [],[]\n",
        "for ii,(X_,y_) in enumerate(gen_train):\n",
        "    X_train.append(X_)\n",
        "    y_train.append(y_[0])\n",
        "    if ii >= gen_train.n - 1:\n",
        "        break\n",
        "X_valid,y_valid = [],[]\n",
        "for ii,(X_,y_) in enumerate(gen_valid):\n",
        "    X_valid.append(X_)\n",
        "    y_valid.append(y_[0])\n",
        "    if ii >= gen_valid.n - 1:\n",
        "        break\n",
        "process_function = partial(process_func,noise_level = 1e5, brightness_level = 1.)\n",
        "gen             = ImageDataGenerator(preprocessing_function = process_function,)\n",
        "gen_train       = gen.flow_from_directory(os.path.join(working_dir,'train'), # train\n",
        "                                          target_size       = (image_resize,image_resize),  # resize the image\n",
        "                                          batch_size        = 1,                   # batch size\n",
        "                                          class_mode        = class_mode,                # get the labels from the folders\n",
        "                                          shuffle           = False,                         # shuffle for different epochs\n",
        "                                          seed              = 12345,                        # replication purpose\n",
        "                                          )\n",
        "gen_valid       = gen.flow_from_directory(os.path.join(working_dir,'validation'), # validate\n",
        "                                           target_size      = (image_resize,image_resize),  # resize the image\n",
        "                                           batch_size       = 1,                   # batch size\n",
        "                                           class_mode       = class_mode,                # get the labels from the folders\n",
        "                                           shuffle          = False,                         # shuffle for different epochs\n",
        "                                           seed             = 12345,                        # replication purpose\n",
        "                                           )\n",
        "for ii,(X_,_) in enumerate(gen_train):\n",
        "    X_train.append(X_)\n",
        "    y_train.append([0.5,0.5])\n",
        "    if ii >= gen_train.n - 1:\n",
        "        break\n",
        "for ii,(X_,_) in enumerate(gen_valid):\n",
        "    X_valid.append(X_)\n",
        "    y_valid.append([0.5,0.5])\n",
        "    if ii >= gen_valid.n - 1:\n",
        "        break\n",
        "process_function = partial(process_func,noise_level = 0., brightness_level = 0.)\n",
        "gen             = ImageDataGenerator(preprocessing_function = process_function,)\n",
        "gen_train       = gen.flow_from_directory(os.path.join(working_dir,'train'), # train\n",
        "                                          target_size       = (image_resize,image_resize),  # resize the image\n",
        "                                          batch_size        = 1,                   # batch size\n",
        "                                          class_mode        = class_mode,                # get the labels from the folders\n",
        "                                          shuffle           = False,                         # shuffle for different epochs\n",
        "                                          seed              = 12345,                        # replication purpose\n",
        "                                          )\n",
        "gen_valid       = gen.flow_from_directory(os.path.join(working_dir,'validation'), # validate\n",
        "                                           target_size      = (image_resize,image_resize),  # resize the image\n",
        "                                           batch_size       = 1,                   # batch size\n",
        "                                           class_mode       = class_mode,                # get the labels from the folders\n",
        "                                           shuffle          = False,                         # shuffle for different epochs\n",
        "                                           seed             = 12345,                        # replication purpose\n",
        "                                           )\n",
        "for ii,(X_,_) in enumerate(gen_train):\n",
        "    X_train.append(X_)\n",
        "    y_train.append([0.5,0.5])\n",
        "    if ii >= gen_train.n - 1:\n",
        "        break\n",
        "for ii,(X_,_) in enumerate(gen_valid):\n",
        "    X_valid.append(X_)\n",
        "    y_valid.append([0.5,0.5])\n",
        "    if ii >= gen_valid.n - 1:\n",
        "        break"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 360 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 360 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 360 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VnUp08o6Olj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.concatenate(X_train)\n",
        "X_valid = np.concatenate(X_valid)\n",
        "y_train = np.array(y_train)\n",
        "y_valid = np.array(y_valid)\n",
        "X_train,y_train = shuffle(X_train,y_train)\n",
        "X_valid,y_valid = shuffle(X_valid,y_valid)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7n7yIl6BXZaN",
        "colab_type": "text"
      },
      "source": [
        "## helper function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKHEHKtDgjqd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the most important helper function: early stopping and model saving\n",
        "def make_CallBackList(model_name,monitor='val_loss',mode='min',verbose=0,min_delta=1e-4,patience=50,frequency = 1):\n",
        "    from tensorflow.keras.callbacks             import ModelCheckpoint,EarlyStopping\n",
        "    \"\"\"\n",
        "    Make call back function lists for the keras models\n",
        "\n",
        "    Inputs\n",
        "    -------------------------\n",
        "    model_name: directory of where we want to save the model and its name\n",
        "    monitor:    the criterion we used for saving or stopping the model\n",
        "    mode:       min --> lower the better, max --> higher the better\n",
        "    verboser:   printout the monitoring messages\n",
        "    min_delta:  minimum change for early stopping\n",
        "    patience:   temporal windows of the minimum change monitoring\n",
        "    frequency:  temporal window steps of the minimum change monitoring\n",
        "\n",
        "    Return\n",
        "    --------------------------\n",
        "    CheckPoint:     saving the best model\n",
        "    EarlyStopping:  early stoppi\n",
        "    \"\"\"\n",
        "    checkPoint = ModelCheckpoint(model_name,# saving path\n",
        "                                 monitor          = monitor,# saving criterion\n",
        "                                 save_best_only   = True,# save only the best model\n",
        "                                 mode             = mode,# saving criterion\n",
        "                                 verbose          = verbose,# print out (>1) or not (0)\n",
        "                                 )\n",
        "    earlyStop = EarlyStopping(   monitor          = monitor,\n",
        "                                 min_delta        = min_delta,\n",
        "                                 patience         = patience,\n",
        "                                 verbose          = verbose,\n",
        "                                 mode             = mode,\n",
        "                                 )\n",
        "    return [checkPoint,earlyStop]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6s0aheNJXbur",
        "colab_type": "text"
      },
      "source": [
        "## the training process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqPK341nXfVs",
        "colab_type": "text"
      },
      "source": [
        "### transfer learning VGG19\n",
        "\n",
        "1. a hidden layer with 300 neurons\n",
        "2. control for the magnitudes of weights (L2 penalty)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ML8NPv-doo-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "874a06c8-60fe-4f41-c4e9-fb4300ce5a03"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "# after loading the model from the pretrained repository, freeze the parameters\n",
        "print(f'\\nloading {model_name} ...\\n')\n",
        "np.random.seed(12345)\n",
        "tf.random.set_seed(12345)\n",
        "model_loaded    = model_pretrained(weights      = 'imagenet',\n",
        "                                   include_top  = False,\n",
        "                                   input_shape  = (image_resize,image_resize,3),\n",
        "                                   pooling      = 'max',\n",
        "                                   )\n",
        "for layer in model_loaded.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# now, adding 2 more layers: CNN --> 300 --> discriminative prediction\n",
        "fine_tune_model = model_loaded.output\n",
        "#fine_tune_model = layers.Dropout(drop_rate,name = 'feature_drop')(fine_tune_model)\n",
        "fine_tune_model = layers.Dense(300,\n",
        "                               activation                       = tf.keras.activations.selu, # SOTA activation function\n",
        "                               kernel_initializer               = 'lecun_normal', # seggested in documentation\n",
        "                               kernel_regularizer               = regularizers.l2(),\n",
        "#                               activity_regularizer             = regularizers.l1(),\n",
        "#                               use_bias                         = False,                       \n",
        "                               name                             = 'feature'\n",
        "                               )(fine_tune_model)\n",
        "#fine_tune_model = layers.Dropout(drop_rate,name = 'predict_drop')(fine_tune_model)\n",
        "fine_tune_model = layers.Dense(2,\n",
        "                               activation                       = 'softmax',#'sigmoid',\n",
        "#                               use_bias                         = False,\n",
        "                               kernel_regularizer               = regularizers.l2(),\n",
        "#                               activity_regularizer             = regularizers.l1(),\n",
        "                               name                             = 'predict'\n",
        "                               )(fine_tune_model)\n",
        "clf             = models.Model(model_loaded.inputs,fine_tune_model)\n",
        "print(clf.summary())\n",
        "# compile the model with an optimizer, a loss function\n",
        "clf.compile(optimizers.Adam(lr = 1e-4,),\n",
        "            loss_func,\n",
        "            metrics = [tf.keras.metrics.AUC()])\n",
        "saving_model_name   = os.path.join(model_dir,f'{model_name}.h5')\n",
        "callbacks           = make_CallBackList(saving_model_name,\n",
        "                                        monitor                 = 'val_{}'.format(clf.metrics_names[-2]),\n",
        "                                        mode                    = 'min',\n",
        "                                        verbose                 = 0,\n",
        "                                        min_delta               = 1e-4,\n",
        "                                        patience                = patience,\n",
        "                                        frequency               = 1)\n",
        "print(f'training {model_name} ...')\n",
        "\n",
        "clf.fit(X_train,y_train,\n",
        "        epochs                                      = 1000, # arbitrary choice\n",
        "        validation_data                             = (X_valid,y_valid),\n",
        "        callbacks                                   = callbacks,\n",
        "                )"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "loading VGG19_small ...\n",
            "\n",
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 128, 128, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv4 (Conv2D)        (None, 32, 32, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv4 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv4 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling2d (Global (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "feature (Dense)              (None, 300)               153900    \n",
            "_________________________________________________________________\n",
            "predict (Dense)              (None, 2)                 602       \n",
            "=================================================================\n",
            "Total params: 20,178,886\n",
            "Trainable params: 154,502\n",
            "Non-trainable params: 20,024,384\n",
            "_________________________________________________________________\n",
            "None\n",
            "training VGG19_small ...\n",
            "Train on 1080 samples, validate on 120 samples\n",
            "Epoch 1/1000\n",
            "1080/1080 [==============================] - 3s 3ms/sample - loss: 5.2017 - auc: 0.4973 - val_loss: 4.0672 - val_auc: 0.6285\n",
            "Epoch 2/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 3.9057 - auc: 0.7507 - val_loss: 3.5606 - val_auc: 0.8859\n",
            "Epoch 3/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 3.5375 - auc: 0.8490 - val_loss: 3.3733 - val_auc: 0.9060\n",
            "Epoch 4/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 3.3228 - auc: 0.9036 - val_loss: 3.2268 - val_auc: 0.9296\n",
            "Epoch 5/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 3.1595 - auc: 0.9329 - val_loss: 3.0886 - val_auc: 0.9406\n",
            "Epoch 6/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 3.0447 - auc: 0.9523 - val_loss: 2.9634 - val_auc: 0.9466\n",
            "Epoch 7/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 2.9306 - auc: 0.9545 - val_loss: 2.8722 - val_auc: 0.9719\n",
            "Epoch 8/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 2.8182 - auc: 0.9678 - val_loss: 2.7945 - val_auc: 0.9591\n",
            "Epoch 9/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 2.7343 - auc: 0.9608 - val_loss: 2.6977 - val_auc: 0.9679\n",
            "Epoch 10/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 2.6491 - auc: 0.9750 - val_loss: 2.6438 - val_auc: 0.9744\n",
            "Epoch 11/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 2.5689 - auc: 0.9811 - val_loss: 2.5663 - val_auc: 0.9754\n",
            "Epoch 12/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 2.5142 - auc: 0.9841 - val_loss: 2.5294 - val_auc: 0.9636\n",
            "Epoch 13/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 2.4437 - auc: 0.9864 - val_loss: 2.4883 - val_auc: 0.9773\n",
            "Epoch 14/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 2.4073 - auc: 0.9844 - val_loss: 2.3852 - val_auc: 0.9776\n",
            "Epoch 15/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 2.3342 - auc: 0.9875 - val_loss: 2.3316 - val_auc: 0.9877\n",
            "Epoch 16/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 2.2810 - auc: 0.9901 - val_loss: 2.2807 - val_auc: 0.9802\n",
            "Epoch 17/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 2.2480 - auc: 0.9929 - val_loss: 2.2517 - val_auc: 0.9804\n",
            "Epoch 18/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 2.1990 - auc: 0.9882 - val_loss: 2.2285 - val_auc: 0.9801\n",
            "Epoch 19/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 2.1547 - auc: 0.9846 - val_loss: 2.1717 - val_auc: 0.9861\n",
            "Epoch 20/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 2.1056 - auc: 0.9908 - val_loss: 2.1203 - val_auc: 0.9831\n",
            "Epoch 21/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 2.0666 - auc: 0.9939 - val_loss: 2.0849 - val_auc: 0.9921\n",
            "Epoch 22/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 2.0460 - auc: 0.9941 - val_loss: 2.0626 - val_auc: 0.9827\n",
            "Epoch 23/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 2.0101 - auc: 0.9931 - val_loss: 2.0254 - val_auc: 0.9816\n",
            "Epoch 24/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.9752 - auc: 0.9884 - val_loss: 1.9948 - val_auc: 0.9926\n",
            "Epoch 25/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.9465 - auc: 0.9922 - val_loss: 2.0043 - val_auc: 0.9903\n",
            "Epoch 26/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.9211 - auc: 0.9968 - val_loss: 1.9448 - val_auc: 0.9874\n",
            "Epoch 27/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.8886 - auc: 0.9958 - val_loss: 1.9076 - val_auc: 0.9836\n",
            "Epoch 28/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.8619 - auc: 0.9970 - val_loss: 1.8902 - val_auc: 0.9822\n",
            "Epoch 29/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.8455 - auc: 0.9877 - val_loss: 1.8700 - val_auc: 0.9949\n",
            "Epoch 30/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.8234 - auc: 0.9921 - val_loss: 1.8400 - val_auc: 0.9949\n",
            "Epoch 31/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.7949 - auc: 0.9969 - val_loss: 1.8208 - val_auc: 0.9932\n",
            "Epoch 32/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.7748 - auc: 0.9927 - val_loss: 1.8008 - val_auc: 0.9821\n",
            "Epoch 33/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.7659 - auc: 0.9926 - val_loss: 1.7880 - val_auc: 0.9950\n",
            "Epoch 34/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.7355 - auc: 0.9908 - val_loss: 1.7588 - val_auc: 0.9952\n",
            "Epoch 35/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.7156 - auc: 0.9927 - val_loss: 1.7492 - val_auc: 0.9832\n",
            "Epoch 36/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.6971 - auc: 0.9891 - val_loss: 1.7202 - val_auc: 0.9949\n",
            "Epoch 37/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.6759 - auc: 0.9973 - val_loss: 1.7218 - val_auc: 0.9829\n",
            "Epoch 38/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.6650 - auc: 0.9946 - val_loss: 1.6865 - val_auc: 0.9954\n",
            "Epoch 39/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.6421 - auc: 0.9967 - val_loss: 1.6707 - val_auc: 0.9956\n",
            "Epoch 40/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.6268 - auc: 0.9965 - val_loss: 1.6544 - val_auc: 0.9969\n",
            "Epoch 41/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.6214 - auc: 0.9925 - val_loss: 1.6457 - val_auc: 0.9824\n",
            "Epoch 42/1000\n",
            "1080/1080 [==============================] - 3s 3ms/sample - loss: 1.5971 - auc: 0.9974 - val_loss: 1.6266 - val_auc: 0.9962\n",
            "Epoch 43/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.5824 - auc: 0.9958 - val_loss: 1.6063 - val_auc: 0.9967\n",
            "Epoch 44/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.5705 - auc: 0.9948 - val_loss: 1.5954 - val_auc: 0.9970\n",
            "Epoch 45/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.5546 - auc: 0.9981 - val_loss: 1.5785 - val_auc: 0.9967\n",
            "Epoch 46/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.5392 - auc: 0.9956 - val_loss: 1.5629 - val_auc: 0.9964\n",
            "Epoch 47/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.5219 - auc: 0.9977 - val_loss: 1.5480 - val_auc: 0.9961\n",
            "Epoch 48/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.5081 - auc: 0.9990 - val_loss: 1.5408 - val_auc: 0.9971\n",
            "Epoch 49/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.4946 - auc: 0.9994 - val_loss: 1.5232 - val_auc: 0.9985\n",
            "Epoch 50/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.4824 - auc: 0.9996 - val_loss: 1.5118 - val_auc: 0.9971\n",
            "Epoch 51/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.4683 - auc: 0.9998 - val_loss: 1.4954 - val_auc: 0.9980\n",
            "Epoch 52/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.4593 - auc: 0.9907 - val_loss: 1.4867 - val_auc: 0.9952\n",
            "Epoch 53/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.4605 - auc: 0.9810 - val_loss: 1.4901 - val_auc: 0.9799\n",
            "Epoch 54/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.4383 - auc: 0.9946 - val_loss: 1.4609 - val_auc: 0.9963\n",
            "Epoch 55/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.4205 - auc: 1.0000 - val_loss: 1.4515 - val_auc: 0.9901\n",
            "Epoch 56/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.4121 - auc: 0.9961 - val_loss: 1.4469 - val_auc: 0.9847\n",
            "Epoch 57/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.4067 - auc: 0.9938 - val_loss: 1.4365 - val_auc: 0.9979\n",
            "Epoch 58/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.3888 - auc: 0.9998 - val_loss: 1.4134 - val_auc: 0.9984\n",
            "Epoch 59/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.3765 - auc: 0.9997 - val_loss: 1.4034 - val_auc: 0.9973\n",
            "Epoch 60/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.3654 - auc: 0.9997 - val_loss: 1.3929 - val_auc: 0.9994\n",
            "Epoch 61/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.3541 - auc: 0.9977 - val_loss: 1.3818 - val_auc: 0.9971\n",
            "Epoch 62/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.3442 - auc: 0.9978 - val_loss: 1.3728 - val_auc: 0.9903\n",
            "Epoch 63/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.3326 - auc: 1.0000 - val_loss: 1.3595 - val_auc: 0.9973\n",
            "Epoch 64/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.3233 - auc: 0.9963 - val_loss: 1.3620 - val_auc: 0.9967\n",
            "Epoch 65/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.3232 - auc: 0.9987 - val_loss: 1.3459 - val_auc: 0.9974\n",
            "Epoch 66/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.3070 - auc: 0.9936 - val_loss: 1.3333 - val_auc: 0.9967\n",
            "Epoch 67/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.2951 - auc: 0.9976 - val_loss: 1.3230 - val_auc: 0.9975\n",
            "Epoch 68/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.2852 - auc: 1.0000 - val_loss: 1.3173 - val_auc: 0.9845\n",
            "Epoch 69/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.2769 - auc: 0.9995 - val_loss: 1.3132 - val_auc: 0.9980\n",
            "Epoch 70/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.2704 - auc: 0.9996 - val_loss: 1.2955 - val_auc: 0.9989\n",
            "Epoch 71/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.2584 - auc: 0.9997 - val_loss: 1.2830 - val_auc: 0.9992\n",
            "Epoch 72/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.2496 - auc: 0.9977 - val_loss: 1.2773 - val_auc: 0.9996\n",
            "Epoch 73/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.2588 - auc: 0.9957 - val_loss: 1.2736 - val_auc: 0.9981\n",
            "Epoch 74/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.2700 - auc: 0.9986 - val_loss: 1.2654 - val_auc: 0.9976\n",
            "Epoch 75/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.2339 - auc: 0.9996 - val_loss: 1.2513 - val_auc: 0.9981\n",
            "Epoch 76/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.2182 - auc: 1.0000 - val_loss: 1.2431 - val_auc: 0.9974\n",
            "Epoch 77/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.2106 - auc: 0.9997 - val_loss: 1.2508 - val_auc: 0.9976\n",
            "Epoch 78/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.2069 - auc: 0.9965 - val_loss: 1.2254 - val_auc: 0.9987\n",
            "Epoch 79/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.1937 - auc: 1.0000 - val_loss: 1.2258 - val_auc: 0.9984\n",
            "Epoch 80/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.1850 - auc: 0.9978 - val_loss: 1.2116 - val_auc: 0.9987\n",
            "Epoch 81/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.1798 - auc: 0.9957 - val_loss: 1.2051 - val_auc: 0.9988\n",
            "Epoch 82/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.1714 - auc: 1.0000 - val_loss: 1.2021 - val_auc: 0.9833\n",
            "Epoch 83/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.1661 - auc: 0.9998 - val_loss: 1.1856 - val_auc: 0.9996\n",
            "Epoch 84/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.1568 - auc: 1.0000 - val_loss: 1.1811 - val_auc: 0.9981\n",
            "Epoch 85/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.1484 - auc: 0.9998 - val_loss: 1.1744 - val_auc: 0.9990\n",
            "Epoch 86/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.1501 - auc: 0.9982 - val_loss: 1.1719 - val_auc: 0.9989\n",
            "Epoch 87/1000\n",
            "1080/1080 [==============================] - 3s 3ms/sample - loss: 1.1357 - auc: 1.0000 - val_loss: 1.1587 - val_auc: 0.9996\n",
            "Epoch 88/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.1288 - auc: 0.9994 - val_loss: 1.1629 - val_auc: 0.9824\n",
            "Epoch 89/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.1250 - auc: 0.9966 - val_loss: 1.1503 - val_auc: 0.9975\n",
            "Epoch 90/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.1147 - auc: 0.9996 - val_loss: 1.1385 - val_auc: 0.9994\n",
            "Epoch 91/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.1128 - auc: 0.9967 - val_loss: 1.1445 - val_auc: 0.9903\n",
            "Epoch 92/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.1057 - auc: 0.9969 - val_loss: 1.1291 - val_auc: 0.9994\n",
            "Epoch 93/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.0963 - auc: 0.9979 - val_loss: 1.1201 - val_auc: 0.9983\n",
            "Epoch 94/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.0885 - auc: 1.0000 - val_loss: 1.1161 - val_auc: 0.9995\n",
            "Epoch 95/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.0834 - auc: 1.0000 - val_loss: 1.1135 - val_auc: 0.9994\n",
            "Epoch 96/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.0839 - auc: 1.0000 - val_loss: 1.1049 - val_auc: 0.9980\n",
            "Epoch 97/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.0768 - auc: 1.0000 - val_loss: 1.0992 - val_auc: 0.9984\n",
            "Epoch 98/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.0740 - auc: 0.9999 - val_loss: 1.1163 - val_auc: 0.9961\n",
            "Epoch 99/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.0634 - auc: 1.0000 - val_loss: 1.0863 - val_auc: 0.9991\n",
            "Epoch 100/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.0595 - auc: 0.9991 - val_loss: 1.0964 - val_auc: 0.9845\n",
            "Epoch 101/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.0505 - auc: 1.0000 - val_loss: 1.0765 - val_auc: 0.9994\n",
            "Epoch 102/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.0435 - auc: 1.0000 - val_loss: 1.0656 - val_auc: 0.9975\n",
            "Epoch 103/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.0377 - auc: 1.0000 - val_loss: 1.0676 - val_auc: 0.9952\n",
            "Epoch 104/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.0304 - auc: 1.0000 - val_loss: 1.0567 - val_auc: 1.0000\n",
            "Epoch 105/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.0270 - auc: 0.9999 - val_loss: 1.0520 - val_auc: 0.9993\n",
            "Epoch 106/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.0254 - auc: 0.9998 - val_loss: 1.0438 - val_auc: 0.9989\n",
            "Epoch 107/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.0222 - auc: 0.9996 - val_loss: 1.0418 - val_auc: 0.9978\n",
            "Epoch 108/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.0174 - auc: 1.0000 - val_loss: 1.0397 - val_auc: 0.9985\n",
            "Epoch 109/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.0136 - auc: 1.0000 - val_loss: 1.0359 - val_auc: 0.9977\n",
            "Epoch 110/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 1.0043 - auc: 1.0000 - val_loss: 1.0238 - val_auc: 0.9985\n",
            "Epoch 111/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.0014 - auc: 0.9974 - val_loss: 1.0209 - val_auc: 0.9991\n",
            "Epoch 112/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 0.9994 - auc: 0.9893 - val_loss: 1.0134 - val_auc: 0.9993\n",
            "Epoch 113/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 1.0026 - auc: 0.9885 - val_loss: 1.0194 - val_auc: 0.9817\n",
            "Epoch 114/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9857 - auc: 1.0000 - val_loss: 1.0052 - val_auc: 0.9981\n",
            "Epoch 115/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9801 - auc: 0.9998 - val_loss: 1.0102 - val_auc: 0.9988\n",
            "Epoch 116/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9772 - auc: 0.9991 - val_loss: 0.9999 - val_auc: 0.9966\n",
            "Epoch 117/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9692 - auc: 1.0000 - val_loss: 0.9934 - val_auc: 0.9988\n",
            "Epoch 118/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 0.9651 - auc: 0.9989 - val_loss: 0.9876 - val_auc: 0.9994\n",
            "Epoch 119/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9640 - auc: 0.9989 - val_loss: 0.9838 - val_auc: 0.9999\n",
            "Epoch 120/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 0.9567 - auc: 1.0000 - val_loss: 0.9791 - val_auc: 0.9994\n",
            "Epoch 121/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9518 - auc: 1.0000 - val_loss: 0.9756 - val_auc: 0.9989\n",
            "Epoch 122/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 0.9483 - auc: 1.0000 - val_loss: 0.9731 - val_auc: 0.9954\n",
            "Epoch 123/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9502 - auc: 0.9999 - val_loss: 0.9761 - val_auc: 0.9995\n",
            "Epoch 124/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9438 - auc: 0.9998 - val_loss: 0.9648 - val_auc: 0.9963\n",
            "Epoch 125/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9368 - auc: 0.9971 - val_loss: 0.9580 - val_auc: 0.9963\n",
            "Epoch 126/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9310 - auc: 1.0000 - val_loss: 0.9582 - val_auc: 0.9995\n",
            "Epoch 127/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9269 - auc: 1.0000 - val_loss: 0.9477 - val_auc: 0.9998\n",
            "Epoch 128/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9233 - auc: 1.0000 - val_loss: 0.9442 - val_auc: 0.9999\n",
            "Epoch 129/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9192 - auc: 0.9999 - val_loss: 0.9399 - val_auc: 0.9986\n",
            "Epoch 130/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 0.9151 - auc: 1.0000 - val_loss: 0.9375 - val_auc: 0.9983\n",
            "Epoch 131/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9121 - auc: 1.0000 - val_loss: 0.9341 - val_auc: 0.9834\n",
            "Epoch 132/1000\n",
            "1080/1080 [==============================] - 3s 2ms/sample - loss: 0.9072 - auc: 1.0000 - val_loss: 0.9264 - val_auc: 0.9997\n",
            "Epoch 133/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9046 - auc: 1.0000 - val_loss: 0.9217 - val_auc: 0.9999\n",
            "Epoch 134/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9014 - auc: 1.0000 - val_loss: 0.9225 - val_auc: 0.9964\n",
            "Epoch 135/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.8969 - auc: 0.9997 - val_loss: 0.9161 - val_auc: 0.9999\n",
            "Epoch 136/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.8952 - auc: 0.9993 - val_loss: 0.9167 - val_auc: 0.9836\n",
            "Epoch 137/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9017 - auc: 0.9868 - val_loss: 0.9629 - val_auc: 0.9811\n",
            "Epoch 138/1000\n",
            "1080/1080 [==============================] - 2s 2ms/sample - loss: 0.9173 - auc: 0.9841 - val_loss: 0.9229 - val_auc: 0.9799\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6cee69bba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXkywNUlXus6",
        "colab_type": "text"
      },
      "source": [
        "## finally validate the convolutional neural network model after training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drEHXuQigSWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a6b4ac2-5adb-4ac5-fdee-69954409fdbf"
      },
      "source": [
        "gen             = ImageDataGenerator(\n",
        "                                     preprocessing_function = process_func,\n",
        "                                     )\n",
        "gen_valid       = gen.flow_from_directory(os.path.join(working_dir,'validation'), # validate\n",
        "                                           target_size      = (image_resize,image_resize),  # resize the image\n",
        "                                           batch_size       = batch_size,                   # batch size\n",
        "                                           class_mode       = class_mode,                # get the labels from the folders\n",
        "                                           shuffle          = False,                         # shuffle for different epochs\n",
        "                                           seed             = 12345,                        # replication purpose\n",
        "                                           )"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 40 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYFqp74aii9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_true = gen_valid.classes\n",
        "y_pred = clf.predict(gen_valid,steps=np.ceil(gen_valid.n / batch_size),)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71SKTrXsioCz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "cda7e7f3-4034-4ac2-aeb9-ccefc894695d"
      },
      "source": [
        "df_view = pd.DataFrame(y_pred,columns = ['left_pred','right_pred'])\n",
        "df_view['y_true'] = y_true\n",
        "df_view['y_true'] = df_view['y_true'].map({0:'left',1:'right'})\n",
        "df_view['correct'] = y_true == y_pred.argmax(1)\n",
        "print(df_view.round(2))\n",
        "print(f\"score = {roc_auc_score(y_true,y_pred[:,-1]):.4f}\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "    left_pred  right_pred y_true  correct\n",
            "0        1.00        0.00   left     True\n",
            "1        1.00        0.00   left     True\n",
            "2        1.00        0.00   left     True\n",
            "3        1.00        0.00   left     True\n",
            "4        1.00        0.00   left     True\n",
            "5        1.00        0.00   left     True\n",
            "6        1.00        0.00   left     True\n",
            "7        1.00        0.00   left     True\n",
            "8        1.00        0.00   left     True\n",
            "9        1.00        0.00   left     True\n",
            "10       1.00        0.00   left     True\n",
            "11       1.00        0.00   left     True\n",
            "12       1.00        0.00   left     True\n",
            "13       1.00        0.00   left     True\n",
            "14       1.00        0.00   left     True\n",
            "15       0.13        0.87   left    False\n",
            "16       0.95        0.05   left     True\n",
            "17       0.95        0.05   left     True\n",
            "18       1.00        0.00   left     True\n",
            "19       1.00        0.00   left     True\n",
            "20       0.00        1.00  right     True\n",
            "21       0.00        1.00  right     True\n",
            "22       0.00        1.00  right     True\n",
            "23       0.00        1.00  right     True\n",
            "24       0.00        1.00  right     True\n",
            "25       0.00        1.00  right     True\n",
            "26       0.00        1.00  right     True\n",
            "27       0.00        1.00  right     True\n",
            "28       0.00        1.00  right     True\n",
            "29       0.00        1.00  right     True\n",
            "30       0.00        1.00  right     True\n",
            "31       0.00        1.00  right     True\n",
            "32       0.00        1.00  right     True\n",
            "33       0.00        1.00  right     True\n",
            "34       0.00        1.00  right     True\n",
            "35       0.01        0.99  right     True\n",
            "36       0.00        1.00  right     True\n",
            "37       0.00        1.00  right     True\n",
            "38       0.00        1.00  right     True\n",
            "39       0.00        1.00  right     True\n",
            "score = 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAui5791X10i",
        "colab_type": "text"
      },
      "source": [
        "# Bayesian optimization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ju9M4m6-X5ZN",
        "colab_type": "text"
      },
      "source": [
        "## we plan to manipulate 2 aspects of the experiment: noise level and brightness"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zeWwOPemm3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clf.trainable = False\n",
        "for layer in clf.layers:\n",
        "    layer.trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-g6paJOEkdkf",
        "colab_type": "text"
      },
      "source": [
        "## define the inputs and outputs of the experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTXjyVtCjXWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def experiment(noise_level = 1,brightness_level = 0.,):\n",
        "    n_runs = 2\n",
        "    rho = .05\n",
        "    process_function = partial(process_func,noise_level = noise_level, brightness_level = brightness_level)\n",
        "    gen             = ImageDataGenerator(\n",
        "                                            preprocessing_function = process_function, \n",
        "                                            )\n",
        "    data_gen        = gen.flow_from_directory(os.path.join(working_dir,'validation'),\n",
        "                                                target_size       = (image_resize,image_resize),  # resize the image\n",
        "                                                batch_size        = batch_size,                   # batch size\n",
        "                                                class_mode        = 'categorical',                # get the labels from the folders\n",
        "                                                shuffle           = False,                        # shuffle for different epochs\n",
        "                                                seed              = 12345,                        # replication purpose\n",
        "                                                )\n",
        "    y_pred,y_true = [],[]\n",
        "    for run in range(n_runs):\n",
        "        preds       = clf.predict_generator(data_gen,\n",
        "                                            steps   = np.ceil(data_gen.n/batch_size),\n",
        "                                            verbose = 0)\n",
        "        targets     = data_gen.classes\n",
        "\n",
        "        #scores.append(roc_auc_score(targets,y_pred[:,-1]))\n",
        "        #chances.append(roc_auc_score(shuffle(targets),y_pred[:,-1]))\n",
        "        y_true.append(targets)\n",
        "        y_pred.append(preds)\n",
        "\n",
        "    y_pred,y_true = np.concatenate(y_pred),np.concatenate(y_true)\n",
        "    return y_pred,y_true"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvhRZjOPki2U",
        "colab_type": "text"
      },
      "source": [
        "### a simple test of the experiment given some parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCE393o2oDpC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6eb475a0-840d-4243-b565-6de1f4415352"
      },
      "source": [
        "outputs = experiment(noise_level = 1e5,brightness_level = .1)\n",
        "outputs[0].round(3)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 40 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.848, 0.152],\n",
              "       [0.787, 0.213],\n",
              "       [0.75 , 0.25 ],\n",
              "       [0.757, 0.243],\n",
              "       [0.841, 0.159],\n",
              "       [0.769, 0.231],\n",
              "       [0.825, 0.175],\n",
              "       [0.808, 0.192],\n",
              "       [0.816, 0.184],\n",
              "       [0.786, 0.214],\n",
              "       [0.729, 0.271],\n",
              "       [0.789, 0.211],\n",
              "       [0.763, 0.237],\n",
              "       [0.855, 0.145],\n",
              "       [0.684, 0.316],\n",
              "       [0.889, 0.111],\n",
              "       [0.805, 0.195],\n",
              "       [0.735, 0.265],\n",
              "       [0.828, 0.172],\n",
              "       [0.837, 0.163],\n",
              "       [0.803, 0.197],\n",
              "       [0.83 , 0.17 ],\n",
              "       [0.86 , 0.14 ],\n",
              "       [0.778, 0.222],\n",
              "       [0.817, 0.183],\n",
              "       [0.813, 0.187],\n",
              "       [0.803, 0.197],\n",
              "       [0.76 , 0.24 ],\n",
              "       [0.853, 0.147],\n",
              "       [0.747, 0.253],\n",
              "       [0.81 , 0.19 ],\n",
              "       [0.693, 0.307],\n",
              "       [0.821, 0.179],\n",
              "       [0.731, 0.269],\n",
              "       [0.78 , 0.22 ],\n",
              "       [0.723, 0.277],\n",
              "       [0.773, 0.227],\n",
              "       [0.788, 0.212],\n",
              "       [0.74 , 0.26 ],\n",
              "       [0.799, 0.201],\n",
              "       [0.755, 0.245],\n",
              "       [0.875, 0.125],\n",
              "       [0.746, 0.254],\n",
              "       [0.776, 0.224],\n",
              "       [0.705, 0.295],\n",
              "       [0.757, 0.243],\n",
              "       [0.891, 0.109],\n",
              "       [0.829, 0.171],\n",
              "       [0.723, 0.277],\n",
              "       [0.816, 0.184],\n",
              "       [0.785, 0.215],\n",
              "       [0.758, 0.242],\n",
              "       [0.799, 0.201],\n",
              "       [0.847, 0.153],\n",
              "       [0.83 , 0.17 ],\n",
              "       [0.749, 0.251],\n",
              "       [0.796, 0.204],\n",
              "       [0.89 , 0.11 ],\n",
              "       [0.823, 0.177],\n",
              "       [0.829, 0.171],\n",
              "       [0.778, 0.222],\n",
              "       [0.912, 0.088],\n",
              "       [0.75 , 0.25 ],\n",
              "       [0.83 , 0.17 ],\n",
              "       [0.69 , 0.31 ],\n",
              "       [0.769, 0.231],\n",
              "       [0.853, 0.147],\n",
              "       [0.798, 0.202],\n",
              "       [0.782, 0.218],\n",
              "       [0.717, 0.283],\n",
              "       [0.773, 0.227],\n",
              "       [0.764, 0.236],\n",
              "       [0.812, 0.188],\n",
              "       [0.8  , 0.2  ],\n",
              "       [0.768, 0.232],\n",
              "       [0.731, 0.269],\n",
              "       [0.707, 0.293],\n",
              "       [0.777, 0.223],\n",
              "       [0.78 , 0.22 ],\n",
              "       [0.763, 0.237]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4Sh6cvmknhE",
        "colab_type": "text"
      },
      "source": [
        "## Bayesian OptimizatiOn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvrfLsAxSPAN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#!pip install scikit-optimize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LVSIBctoR9aB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "outputId": "cfe1aa36-cc63-48d0-ac28-31ce3692a385"
      },
      "source": [
        "import skopt"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDVATUnnSLjU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skopt import gp_minimize,callbacks\n",
        "from skopt.space import Real\n",
        "from skopt.utils import use_named_args\n",
        "def cross_entropy(p, q):\n",
        "\treturn -sum([p[i]*np.log2(q[i]) for i in range(len(p))])\n",
        "from sklearn import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vxLFLSy4hzvt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "bfae1fcc-c320-4484-ea94-dc40a550be10"
      },
      "source": [
        "space = [Real(1e-7,1e4,prior='uniform',name = 'noise_level'),\n",
        "         Real(0,1.,prior='uniform',name = 'brightness_level')]\n",
        "@use_named_args(space)\n",
        "def objective(**params):\n",
        "    rho = 0.5\n",
        "    y_pred,y_true = experiment(**params)\n",
        "    accuracy = cross_entropy(y_true,y_pred[:,-1])\n",
        "    confidence = np.abs(np.ones(y_pred.shape[0]) * .5 -  y_pred.max(1)).sum()\n",
        "    return rho * accuracy + (1 - rho) * confidence\n",
        "rho = 0.5\n",
        "y_pred,y_true = experiment(**{'noise_level':0,'brightness_level':1.})\n",
        "accuracy = cross_entropy(y_true,y_pred[:,-1])\n",
        "confidence = confidence = np.abs(np.ones(y_pred.shape[0]) * .5 -  y_pred.max(1)).sum()\n",
        "print(rho * accuracy + (1 - rho) * confidence)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 40 images belonging to 2 classes.\n",
            "19.769308695915697\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yk4Sw9JhC9ij",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "outputId": "847485ef-8fef-463b-ffe0-94eda5d11430"
      },
      "source": [
        "res_gp = gp_minimize(objective, space, n_calls=int(1e2), random_state=12345,acq_func = 'EI',x0 = [1e-4,1.],\n",
        "                     callback = callbacks.DeltaYStopper(delta=1e-3),\n",
        "                     kappa = 10,)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYoCOt_ITNnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from skopt.plots import plot_convergence\n",
        "plot_convergence(res_gp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRQq2Wm4lvCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res_gp.x_iters"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq1j-5tYnhTR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}